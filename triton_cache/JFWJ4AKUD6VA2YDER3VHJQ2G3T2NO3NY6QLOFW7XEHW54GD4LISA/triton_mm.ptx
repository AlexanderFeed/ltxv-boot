//
// Generated by LLVM NVPTX Back-End
//

.version 8.4
.target sm_86
.address_size 64

	// .globl	triton_mm               // -- Begin function triton_mm
.extern .shared .align 16 .b8 global_smem[];
                                        // @triton_mm
.visible .entry triton_mm(
	.param .u64 .ptr .global .align 1 triton_mm_param_0,
	.param .u64 .ptr .global .align 1 triton_mm_param_1,
	.param .u64 .ptr .global .align 1 triton_mm_param_2,
	.param .u64 .ptr .global .align 1 triton_mm_param_3
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<29>;
	.reg .b16 	%rs<33>;
	.reg .b32 	%r<332>;
	.reg .f32 	%f<226>;
	.reg .b64 	%rd<45>;
	.loc	1 17 0                          // cctuvsvbq3ot32efv6u3s5qokncb7a6dvqo3oxdb3yqmw33vi56g.py:17:0
$L__func_begin0:
	.loc	1 17 0                          // cctuvsvbq3ot32efv6u3s5qokncb7a6dvqo3oxdb3yqmw33vi56g.py:17:0

// %bb.0:
	ld.param.u64 	%rd7, [triton_mm_param_2];
	ld.param.u64 	%rd13, [triton_mm_param_0];
	ld.param.u64 	%rd14, [triton_mm_param_1];
$L__tmp0:
	.loc	1 40 24                         // cctuvsvbq3ot32efv6u3s5qokncb7a6dvqo3oxdb3yqmw33vi56g.py:40:24
	mov.u32 	%r28, %ctaid.x;
	.loc	1 46 22                         // cctuvsvbq3ot32efv6u3s5qokncb7a6dvqo3oxdb3yqmw33vi56g.py:46:22
	mul.hi.s32 	%r29, %r28, 1717986919;
	shr.u32 	%r30, %r29, 31;
	shr.s32 	%r31, %r29, 9;
	add.s32 	%r32, %r31, %r30;
	.loc	1 47 41                         // cctuvsvbq3ot32efv6u3s5qokncb7a6dvqo3oxdb3yqmw33vi56g.py:47:41
	shl.b32 	%r33, %r32, 3;
	.loc	1 47 30                         // cctuvsvbq3ot32efv6u3s5qokncb7a6dvqo3oxdb3yqmw33vi56g.py:47:30
	sub.s32 	%r34, 8, %r33;
	.loc	1 47 50                         // cctuvsvbq3ot32efv6u3s5qokncb7a6dvqo3oxdb3yqmw33vi56g.py:47:50
	min.s32 	%r35, %r34, 8;
	.loc	1 48 40                         // cctuvsvbq3ot32efv6u3s5qokncb7a6dvqo3oxdb3yqmw33vi56g.py:48:40
	rem.s32 	%r36, %r28, %r35;
	.loc	1 48 34                         // cctuvsvbq3ot32efv6u3s5qokncb7a6dvqo3oxdb3yqmw33vi56g.py:48:34
	add.s32 	%r37, %r36, %r33;
	.loc	1 49 19                         // cctuvsvbq3ot32efv6u3s5qokncb7a6dvqo3oxdb3yqmw33vi56g.py:49:19
	mul.lo.s32 	%r38, %r32, 1280;
	sub.s32 	%r39, %r28, %r38;
	.loc	1 49 30                         // cctuvsvbq3ot32efv6u3s5qokncb7a6dvqo3oxdb3yqmw33vi56g.py:49:30
	div.s32 	%r40, %r39, %r35;
	.loc	1 51 17                         // cctuvsvbq3ot32efv6u3s5qokncb7a6dvqo3oxdb3yqmw33vi56g.py:51:17
	shl.b32 	%r1, %r37, 6;
	.loc	1 51 40                         // cctuvsvbq3ot32efv6u3s5qokncb7a6dvqo3oxdb3yqmw33vi56g.py:51:40
	mov.u32 	%r2, %tid.x;
	and.b32  	%r41, %r2, 8;
	shr.u32 	%r42, %r2, 2;
	and.b32  	%r3, %r42, 8;
	and.b32  	%r43, %r42, 16;
	bfe.u32 	%r44, %r2, 2, 5;
	or.b32  	%r45, %r44, 32;
	shl.b32 	%r4, %r2, 3;
	and.b32  	%r46, %r4, 24;
	.loc	1 51 27                         // cctuvsvbq3ot32efv6u3s5qokncb7a6dvqo3oxdb3yqmw33vi56g.py:51:27
	or.b32  	%r47, %r1, %r44;
	or.b32  	%r48, %r1, %r45;
	.loc	1 52 17                         // cctuvsvbq3ot32efv6u3s5qokncb7a6dvqo3oxdb3yqmw33vi56g.py:52:17
	shl.b32 	%r5, %r40, 6;
	.loc	1 52 27                         // cctuvsvbq3ot32efv6u3s5qokncb7a6dvqo3oxdb3yqmw33vi56g.py:52:27
	or.b32  	%r49, %r5, %r44;
	or.b32  	%r50, %r5, %r45;
	.loc	1 54 57                         // cctuvsvbq3ot32efv6u3s5qokncb7a6dvqo3oxdb3yqmw33vi56g.py:54:57
	bfe.s32 	%r51, %r37, 25, 1;
	shr.u32 	%r52, %r51, 23;
	add.s32 	%r53, %r47, %r52;
	and.b32  	%r54, %r53, 1048064;
	sub.s32 	%r55, %r47, %r54;
	add.s32 	%r56, %r48, %r52;
	and.b32  	%r57, %r56, 1048064;
	sub.s32 	%r58, %r48, %r57;
	.loc	1 58 57                         // cctuvsvbq3ot32efv6u3s5qokncb7a6dvqo3oxdb3yqmw33vi56g.py:58:57
	mul.hi.s32 	%r59, %r49, 1717986919;
	shr.u32 	%r60, %r59, 31;
	shr.u32 	%r61, %r59, 12;
	add.s32 	%r62, %r61, %r60;
	mul.lo.s32 	%r63, %r62, 10240;
	sub.s32 	%r64, %r49, %r63;
	mul.hi.s32 	%r65, %r50, 1717986919;
	shr.u32 	%r66, %r65, 31;
	shr.u32 	%r67, %r65, 12;
	add.s32 	%r68, %r67, %r66;
	mul.lo.s32 	%r69, %r68, 10240;
	sub.s32 	%r70, %r50, %r69;
	.loc	1 71 30                         // cctuvsvbq3ot32efv6u3s5qokncb7a6dvqo3oxdb3yqmw33vi56g.py:71:30
	shl.b32 	%r71, %r55, 12;
	shl.b32 	%r72, %r58, 12;
	.loc	1 77 55                         // cctuvsvbq3ot32efv6u3s5qokncb7a6dvqo3oxdb3yqmw33vi56g.py:77:55
	shl.b32 	%r73, %r64, 12;
	shl.b32 	%r74, %r70, 12;
	.loc	1 71 25                         // cctuvsvbq3ot32efv6u3s5qokncb7a6dvqo3oxdb3yqmw33vi56g.py:71:25
	or.b32  	%r75, %r71, %r46;
	or.b32  	%r76, %r72, %r46;
	.loc	1 72 25                         // cctuvsvbq3ot32efv6u3s5qokncb7a6dvqo3oxdb3yqmw33vi56g.py:72:25
	mul.wide.s32 	%rd15, %r75, 2;
	add.s64 	%rd8, %rd13, %rd15;
	mul.wide.s32 	%rd16, %r76, 2;
	add.s64 	%rd9, %rd13, %rd16;
	.loc	1 72 20                         // cctuvsvbq3ot32efv6u3s5qokncb7a6dvqo3oxdb3yqmw33vi56g.py:72:20
	xor.b32  	%r77, %r4, %r2;
	and.b32  	%r78, %r77, 24;
	shl.b32 	%r79, %r78, 1;
	shl.b32 	%r80, %r44, 6;
	or.b32  	%r81, %r80, %r79;
	mov.u32 	%r82, global_smem;
	add.s32 	%r242, %r82, %r81;
	add.s32 	%r244, %r242, 2048;
	mov.b32 	%r20, 16;
	// begin inline asm
	cp.async.cg.shared.global [ %r242 + 0 ], [ %rd8 + 0 ], 0x10, %r20;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r244 + 0 ], [ %rd9 + 0 ], 0x10, %r20;
	// end inline asm
	cp.async.commit_group;
	.loc	1 77 50                         // cctuvsvbq3ot32efv6u3s5qokncb7a6dvqo3oxdb3yqmw33vi56g.py:77:50
	or.b32  	%r83, %r73, %r46;
	or.b32  	%r84, %r74, %r46;
	.loc	1 77 25                         // cctuvsvbq3ot32efv6u3s5qokncb7a6dvqo3oxdb3yqmw33vi56g.py:77:25
	mul.wide.s32 	%rd17, %r83, 2;
	add.s64 	%rd10, %rd14, %rd17;
	mul.wide.s32 	%rd18, %r84, 2;
	add.s64 	%rd11, %rd14, %rd18;
	.loc	1 77 20                         // cctuvsvbq3ot32efv6u3s5qokncb7a6dvqo3oxdb3yqmw33vi56g.py:77:20
	add.s32 	%r23, %r242, 4096;
	add.s32 	%r25, %r242, 6144;
	// begin inline asm
	cp.async.cg.shared.global [ %r23 + 0 ], [ %rd10 + 0 ], 0x10, %r20;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r25 + 0 ], [ %rd11 + 0 ], 0x10, %r20;
	// end inline asm
	cp.async.commit_group;
	.loc	1 64 26                         // cctuvsvbq3ot32efv6u3s5qokncb7a6dvqo3oxdb3yqmw33vi56g.py:64:26
	or.b32  	%r85, %r41, %r43;
	and.b32  	%r86, %r2, 7;
	or.b32  	%r87, %r85, %r86;
	shl.b32 	%r88, %r2, 2;
	and.b32  	%r89, %r88, 8;
	and.b32  	%r90, %r88, 16;
	and.b32  	%r91, %r88, 24;
	and.b32  	%r92, %r2, 15;
	shr.u32 	%r93, %r2, 1;
	and.b32  	%r94, %r93, 8;
	xor.b32  	%r95, %r91, %r94;
	or.b32  	%r96, %r43, %r92;
	shl.b32 	%r97, %r96, 5;
	or.b32  	%r10, %r95, %r97;
	or.b32  	%r98, %r89, 16;
	or.b32  	%r99, %r94, %r90;
	xor.b32  	%r100, %r99, %r98;
	or.b32  	%r11, %r100, %r97;
	shl.b32 	%r101, %r87, 5;
	or.b32  	%r102, %r101, 1024;
	or.b32  	%r12, %r102, %r95;
	or.b32  	%r13, %r100, %r102;
	xor.b32  	%r103, %r88, %r2;
	and.b32  	%r14, %r103, 24;
	or.b32  	%r104, %r3, %r86;
	shl.b32 	%r15, %r104, 5;
	or.b32  	%r16, %r14, %r15;
	and.b32  	%r105, %r2, 3;
	mul.wide.u32 	%rd19, %r105, 16;
	mul.wide.s32 	%rd20, %r74, 2;
	or.b64  	%rd21, %rd19, %rd20;
	add.s64 	%rd22, %rd21, %rd14;
	add.s64 	%rd1, %rd22, 64;
	mul.wide.s32 	%rd23, %r73, 2;
	or.b64  	%rd24, %rd19, %rd23;
	add.s64 	%rd25, %rd24, %rd14;
	add.s64 	%rd2, %rd25, 64;
	mul.wide.s32 	%rd26, %r72, 2;
	or.b64  	%rd27, %rd19, %rd26;
	add.s64 	%rd28, %rd27, %rd13;
	add.s64 	%rd3, %rd28, 64;
	mul.wide.s32 	%rd29, %r71, 2;
	or.b64  	%rd30, %rd19, %rd29;
	add.s64 	%rd31, %rd30, %rd13;
	add.s64 	%rd4, %rd31, 64;
	mov.f32 	%f194, 0f00000000;
	mov.b32 	%r331, -1;
	mov.b64 	%rd44, 0;
	shl.b32 	%r254, %r10, 1;
	shl.b32 	%r255, %r11, 1;
	shl.b32 	%r256, %r12, 1;
	shl.b32 	%r257, %r13, 1;
	shl.b32 	%r259, %r16, 1;
	mov.f32 	%f195, %f194;
	mov.f32 	%f196, %f194;
	mov.f32 	%f197, %f194;
	mov.f32 	%f198, %f194;
	mov.f32 	%f199, %f194;
	mov.f32 	%f200, %f194;
	mov.f32 	%f201, %f194;
	mov.f32 	%f202, %f194;
	mov.f32 	%f203, %f194;
	mov.f32 	%f204, %f194;
	mov.f32 	%f205, %f194;
	mov.f32 	%f206, %f194;
	mov.f32 	%f207, %f194;
	mov.f32 	%f208, %f194;
	mov.f32 	%f209, %f194;
	mov.f32 	%f210, %f194;
	mov.f32 	%f211, %f194;
	mov.f32 	%f212, %f194;
	mov.f32 	%f213, %f194;
	mov.f32 	%f214, %f194;
	mov.f32 	%f215, %f194;
	mov.f32 	%f216, %f194;
	mov.f32 	%f217, %f194;
	mov.f32 	%f218, %f194;
	mov.f32 	%f219, %f194;
	mov.f32 	%f220, %f194;
	mov.f32 	%f221, %f194;
	mov.f32 	%f222, %f194;
	mov.f32 	%f223, %f194;
	mov.f32 	%f224, %f194;
	mov.f32 	%f225, %f194;
$L__BB0_1:                              // =>This Inner Loop Header: Depth=1
	setp.eq.s64 	%p1, %rd44, 8128;
	add.s32 	%r250, %r331, 1;
	setp.gt.u32 	%p2, %r331, 2147483646;
	selp.b32 	%r331, %r250, 0, %p2;
	.loc	1 72 20                         // cctuvsvbq3ot32efv6u3s5qokncb7a6dvqo3oxdb3yqmw33vi56g.py:72:20
	cp.async.wait_group 0;
	bar.sync 	0;
	shl.b32 	%r251, %r331, 12;
	add.s32 	%r253, %r82, %r251;
	add.s32 	%r110, %r253, %r254;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r146, %r147, %r148, %r149}, [%r110];
	// end inline asm
	add.s32 	%r115, %r253, %r255;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r194, %r195, %r196, %r197}, [%r115];
	// end inline asm
	add.s32 	%r120, %r253, %r256;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r170, %r171, %r172, %r173}, [%r120];
	// end inline asm
	add.s32 	%r125, %r253, %r257;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r218, %r219, %r220, %r221}, [%r125];
	// end inline asm
	.loc	1 77 20                         // cctuvsvbq3ot32efv6u3s5qokncb7a6dvqo3oxdb3yqmw33vi56g.py:77:20
	add.s32 	%r258, %r253, 4096;
	add.s32 	%r130, %r258, %r259;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r150, %r151, %r198, %r199}, [%r130];
	// end inline asm
	add.s32 	%r135, %r130, 1024;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r156, %r157, %r204, %r205}, [%r135];
	// end inline asm
	add.s32 	%r260, %r14, %r15;
	shl.b32 	%r261, %r260, 1;
	add.s32 	%r262, %r258, %r261;
	add.s32 	%r140, %r262, 2048;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r162, %r163, %r210, %r211}, [%r140];
	// end inline asm
	add.s32 	%r145, %r130, 3072;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r168, %r169, %r216, %r217}, [%r145];
	// end inline asm
	.loc	1 78 25                         // cctuvsvbq3ot32efv6u3s5qokncb7a6dvqo3oxdb3yqmw33vi56g.py:78:25
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f194, %f195, %f196, %f197 }, { %r146, %r147, %r148, %r149 }, { %r150, %r151 }, { %f194, %f195, %f196, %f197 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f198, %f199, %f200, %f201 }, { %r146, %r147, %r148, %r149 }, { %r156, %r157 }, { %f198, %f199, %f200, %f201 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f202, %f203, %f204, %f205 }, { %r146, %r147, %r148, %r149 }, { %r162, %r163 }, { %f202, %f203, %f204, %f205 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f206, %f207, %f208, %f209 }, { %r146, %r147, %r148, %r149 }, { %r168, %r169 }, { %f206, %f207, %f208, %f209 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f210, %f211, %f212, %f213 }, { %r170, %r171, %r172, %r173 }, { %r150, %r151 }, { %f210, %f211, %f212, %f213 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f214, %f215, %f216, %f217 }, { %r170, %r171, %r172, %r173 }, { %r156, %r157 }, { %f214, %f215, %f216, %f217 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f218, %f219, %f220, %f221 }, { %r170, %r171, %r172, %r173 }, { %r162, %r163 }, { %f218, %f219, %f220, %f221 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f222, %f223, %f224, %f225 }, { %r170, %r171, %r172, %r173 }, { %r168, %r169 }, { %f222, %f223, %f224, %f225 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f194, %f195, %f196, %f197 }, { %r194, %r195, %r196, %r197 }, { %r198, %r199 }, { %f194, %f195, %f196, %f197 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f198, %f199, %f200, %f201 }, { %r194, %r195, %r196, %r197 }, { %r204, %r205 }, { %f198, %f199, %f200, %f201 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f202, %f203, %f204, %f205 }, { %r194, %r195, %r196, %r197 }, { %r210, %r211 }, { %f202, %f203, %f204, %f205 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f206, %f207, %f208, %f209 }, { %r194, %r195, %r196, %r197 }, { %r216, %r217 }, { %f206, %f207, %f208, %f209 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f210, %f211, %f212, %f213 }, { %r218, %r219, %r220, %r221 }, { %r198, %r199 }, { %f210, %f211, %f212, %f213 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f214, %f215, %f216, %f217 }, { %r218, %r219, %r220, %r221 }, { %r204, %r205 }, { %f214, %f215, %f216, %f217 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f218, %f219, %f220, %f221 }, { %r218, %r219, %r220, %r221 }, { %r210, %r211 }, { %f218, %f219, %f220, %f221 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f222, %f223, %f224, %f225 }, { %r218, %r219, %r220, %r221 }, { %r216, %r217 }, { %f222, %f223, %f224, %f225 };
	// end inline asm
	.loc	1 72 25                         // cctuvsvbq3ot32efv6u3s5qokncb7a6dvqo3oxdb3yqmw33vi56g.py:72:25
	add.s64 	%rd32, %rd4, %rd44;
	.loc	1 72 20                         // cctuvsvbq3ot32efv6u3s5qokncb7a6dvqo3oxdb3yqmw33vi56g.py:72:20
	add.s64 	%rd33, %rd3, %rd44;
	bar.sync 	0;
	selp.b32 	%r243, 0, 16, %p1;
	// begin inline asm
	cp.async.cg.shared.global [ %r242 + 0 ], [ %rd32 + 0 ], 0x10, %r243;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r244 + 0 ], [ %rd33 + 0 ], 0x10, %r243;
	// end inline asm
	cp.async.commit_group;
	.loc	1 77 25                         // cctuvsvbq3ot32efv6u3s5qokncb7a6dvqo3oxdb3yqmw33vi56g.py:77:25
	add.s64 	%rd34, %rd2, %rd44;
	.loc	1 77 20                         // cctuvsvbq3ot32efv6u3s5qokncb7a6dvqo3oxdb3yqmw33vi56g.py:77:20
	add.s64 	%rd35, %rd1, %rd44;
	// begin inline asm
	cp.async.cg.shared.global [ %r23 + 0 ], [ %rd34 + 0 ], 0x10, %r243;
	// end inline asm
	// begin inline asm
	cp.async.cg.shared.global [ %r25 + 0 ], [ %rd35 + 0 ], 0x10, %r243;
	// end inline asm
	cp.async.commit_group;
	.loc	1 64 26                         // cctuvsvbq3ot32efv6u3s5qokncb7a6dvqo3oxdb3yqmw33vi56g.py:64:26
	add.s64 	%rd44, %rd44, 64;
	setp.ne.s64 	%p3, %rd44, 8192;
	@%p3 bra 	$L__BB0_1;
// %bb.2:
	.loc	1 51 40                         // cctuvsvbq3ot32efv6u3s5qokncb7a6dvqo3oxdb3yqmw33vi56g.py:51:40
	and.b32  	%r295, %r4, 56;
	.loc	1 52 27                         // cctuvsvbq3ot32efv6u3s5qokncb7a6dvqo3oxdb3yqmw33vi56g.py:52:27
	or.b32  	%r296, %r5, %r295;
	.loc	1 51 40                         // cctuvsvbq3ot32efv6u3s5qokncb7a6dvqo3oxdb3yqmw33vi56g.py:51:40
	bfe.u32 	%r297, %r2, 3, 4;
	.loc	1 51 27                         // cctuvsvbq3ot32efv6u3s5qokncb7a6dvqo3oxdb3yqmw33vi56g.py:51:27
	or.b32  	%r298, %r297, %r1;
	or.b32  	%r299, %r298, 48;
	or.b32  	%r300, %r298, 32;
	or.b32  	%r301, %r298, 16;
	.loc	1 64 26                         // cctuvsvbq3ot32efv6u3s5qokncb7a6dvqo3oxdb3yqmw33vi56g.py:64:26
	cp.async.wait_group 0;
	bar.sync 	0;
	.loc	1 85 20                         // cctuvsvbq3ot32efv6u3s5qokncb7a6dvqo3oxdb3yqmw33vi56g.py:85:20
	setp.lt.s32 	%p24, %r298, 512;
	setp.lt.s32 	%p25, %r301, 512;
	setp.lt.s32 	%p26, %r300, 512;
	setp.lt.s32 	%p27, %r299, 512;
	.loc	1 85 34                         // cctuvsvbq3ot32efv6u3s5qokncb7a6dvqo3oxdb3yqmw33vi56g.py:85:34
	setp.lt.s32 	%p28, %r296, 10240;
	.loc	1 85 26                         // cctuvsvbq3ot32efv6u3s5qokncb7a6dvqo3oxdb3yqmw33vi56g.py:85:26
	and.pred  	%p20, %p24, %p28;
	and.pred  	%p21, %p25, %p28;
	and.pred  	%p22, %p26, %p28;
	and.pred  	%p23, %p27, %p28;
	.loc	1 88 27                         // cctuvsvbq3ot32efv6u3s5qokncb7a6dvqo3oxdb3yqmw33vi56g.py:88:27
	mad.lo.s32 	%r302, %r298, 10240, %r296;
	add.s32 	%r303, %r302, 163840;
	add.s32 	%r304, %r302, 327680;
	.loc	1 88 21                         // cctuvsvbq3ot32efv6u3s5qokncb7a6dvqo3oxdb3yqmw33vi56g.py:88:21
	add.s32 	%r305, %r302, 491520;
	.loc	1 89 25                         // cctuvsvbq3ot32efv6u3s5qokncb7a6dvqo3oxdb3yqmw33vi56g.py:89:25
	mul.wide.s32 	%rd40, %r302, 2;
	add.s64 	%rd36, %rd7, %rd40;
	mul.wide.s32 	%rd41, %r303, 2;
	add.s64 	%rd37, %rd7, %rd41;
	mul.wide.s32 	%rd42, %r304, 2;
	add.s64 	%rd38, %rd7, %rd42;
	mul.wide.s32 	%rd43, %r305, 2;
	add.s64 	%rd39, %rd7, %rd43;
	.loc	1 89 67                         // cctuvsvbq3ot32efv6u3s5qokncb7a6dvqo3oxdb3yqmw33vi56g.py:89:67
	cvt.rn.bf16.f32 	%rs1, %f194;
	cvt.rn.bf16.f32 	%rs2, %f195;
	cvt.rn.bf16.f32 	%rs3, %f196;
	cvt.rn.bf16.f32 	%rs4, %f197;
	cvt.rn.bf16.f32 	%rs5, %f198;
	cvt.rn.bf16.f32 	%rs6, %f199;
	cvt.rn.bf16.f32 	%rs7, %f200;
	cvt.rn.bf16.f32 	%rs8, %f201;
	cvt.rn.bf16.f32 	%rs9, %f202;
	cvt.rn.bf16.f32 	%rs10, %f203;
	cvt.rn.bf16.f32 	%rs11, %f204;
	cvt.rn.bf16.f32 	%rs12, %f205;
	cvt.rn.bf16.f32 	%rs13, %f206;
	cvt.rn.bf16.f32 	%rs14, %f207;
	cvt.rn.bf16.f32 	%rs15, %f208;
	cvt.rn.bf16.f32 	%rs16, %f209;
	cvt.rn.bf16.f32 	%rs17, %f210;
	cvt.rn.bf16.f32 	%rs18, %f211;
	cvt.rn.bf16.f32 	%rs19, %f212;
	cvt.rn.bf16.f32 	%rs20, %f213;
	cvt.rn.bf16.f32 	%rs21, %f214;
	cvt.rn.bf16.f32 	%rs22, %f215;
	cvt.rn.bf16.f32 	%rs23, %f216;
	cvt.rn.bf16.f32 	%rs24, %f217;
	cvt.rn.bf16.f32 	%rs25, %f218;
	cvt.rn.bf16.f32 	%rs26, %f219;
	cvt.rn.bf16.f32 	%rs27, %f220;
	cvt.rn.bf16.f32 	%rs28, %f221;
	cvt.rn.bf16.f32 	%rs29, %f222;
	cvt.rn.bf16.f32 	%rs30, %f223;
	cvt.rn.bf16.f32 	%rs31, %f224;
	cvt.rn.bf16.f32 	%rs32, %f225;
	shl.b32 	%r306, %r2, 1;
	and.b32  	%r307, %r306, 6;
	shl.b32 	%r308, %r2, 4;
	and.b32  	%r309, %r308, 1472;
	or.b32  	%r310, %r309, %r307;
	or.b32  	%r311, %r310, %r3;
	and.b32  	%r312, %r4, 1016;
	shr.u32 	%r313, %r309, 2;
	add.s32 	%r315, %r82, %r313;
	shl.b32 	%r316, %r311, 1;
	add.s32 	%r263, %r315, %r316;
	mov.pred 	%p4, -1;
	// begin inline asm
	@%p4 st.shared.v2.b16 [ %r263 + 0 ], { %rs1, %rs2 };
	// end inline asm
	or.b32  	%r317, %r309, 512;
	shr.u32 	%r318, %r317, 2;
	add.s32 	%r319, %r82, %r318;
	add.s32 	%r320, %r319, %r316;
	add.s32 	%r264, %r320, 1024;
	// begin inline asm
	@%p4 st.shared.v2.b16 [ %r264 + 0 ], { %rs3, %rs4 };
	// end inline asm
	add.s32 	%r265, %r263, 32;
	// begin inline asm
	@%p4 st.shared.v2.b16 [ %r265 + 0 ], { %rs5, %rs6 };
	// end inline asm
	add.s32 	%r266, %r320, 1056;
	// begin inline asm
	@%p4 st.shared.v2.b16 [ %r266 + 0 ], { %rs7, %rs8 };
	// end inline asm
	add.s32 	%r267, %r263, 64;
	// begin inline asm
	@%p4 st.shared.v2.b16 [ %r267 + 0 ], { %rs9, %rs10 };
	// end inline asm
	add.s32 	%r268, %r320, 1088;
	// begin inline asm
	@%p4 st.shared.v2.b16 [ %r268 + 0 ], { %rs11, %rs12 };
	// end inline asm
	add.s32 	%r269, %r263, 96;
	// begin inline asm
	@%p4 st.shared.v2.b16 [ %r269 + 0 ], { %rs13, %rs14 };
	// end inline asm
	add.s32 	%r270, %r320, 1120;
	// begin inline asm
	@%p4 st.shared.v2.b16 [ %r270 + 0 ], { %rs15, %rs16 };
	// end inline asm
	bar.sync 	0;
	and.b32  	%r321, %r2, 120;
	shl.b32 	%r322, %r321, 1;
	add.s32 	%r323, %r82, %r322;
	shl.b32 	%r324, %r312, 1;
	add.s32 	%r325, %r323, %r324;
	ld.shared.v4.u32 	{%r279, %r280, %r281, %r282}, [%r325];
	or.b32  	%r326, %r312, 1024;
	shr.u32 	%r327, %r326, 2;
	and.b32  	%r328, %r327, 496;
	add.s32 	%r329, %r82, %r328;
	add.s32 	%r330, %r329, %r324;
	ld.shared.v4.u32 	{%r283, %r284, %r285, %r286}, [%r330+2048];
	bar.sync 	0;
	// begin inline asm
	@%p4 st.shared.v2.b16 [ %r263 + 0 ], { %rs17, %rs18 };
	// end inline asm
	// begin inline asm
	@%p4 st.shared.v2.b16 [ %r264 + 0 ], { %rs19, %rs20 };
	// end inline asm
	// begin inline asm
	@%p4 st.shared.v2.b16 [ %r265 + 0 ], { %rs21, %rs22 };
	// end inline asm
	// begin inline asm
	@%p4 st.shared.v2.b16 [ %r266 + 0 ], { %rs23, %rs24 };
	// end inline asm
	// begin inline asm
	@%p4 st.shared.v2.b16 [ %r267 + 0 ], { %rs25, %rs26 };
	// end inline asm
	// begin inline asm
	@%p4 st.shared.v2.b16 [ %r268 + 0 ], { %rs27, %rs28 };
	// end inline asm
	// begin inline asm
	@%p4 st.shared.v2.b16 [ %r269 + 0 ], { %rs29, %rs30 };
	// end inline asm
	// begin inline asm
	@%p4 st.shared.v2.b16 [ %r270 + 0 ], { %rs31, %rs32 };
	// end inline asm
	bar.sync 	0;
	ld.shared.v4.u32 	{%r287, %r288, %r289, %r290}, [%r325];
	ld.shared.v4.u32 	{%r291, %r292, %r293, %r294}, [%r330+2048];
	// begin inline asm
	@%p20 st.global.v4.b32 [ %rd36 + 0 ], { %r279, %r280, %r281, %r282 };
	// end inline asm
	// begin inline asm
	@%p21 st.global.v4.b32 [ %rd37 + 0 ], { %r283, %r284, %r285, %r286 };
	// end inline asm
	// begin inline asm
	@%p22 st.global.v4.b32 [ %rd38 + 0 ], { %r287, %r288, %r289, %r290 };
	// end inline asm
	// begin inline asm
	@%p23 st.global.v4.b32 [ %rd39 + 0 ], { %r291, %r292, %r293, %r294 };
	// end inline asm
	.loc	1 89 4                          // cctuvsvbq3ot32efv6u3s5qokncb7a6dvqo3oxdb3yqmw33vi56g.py:89:4
	ret;
$L__tmp1:
$L__func_end0:
                                        // -- End function
}
	.file	1 "/tmp/torchinductor_root/ct/cctuvsvbq3ot32efv6u3s5qokncb7a6dvqo3oxdb3yqmw33vi56g.py"
	.section	.debug_abbrev
	{
.b8 1                                   // Abbreviation Code
.b8 17                                  // DW_TAG_compile_unit
.b8 0                                   // DW_CHILDREN_no
.b8 37                                  // DW_AT_producer
.b8 8                                   // DW_FORM_string
.b8 19                                  // DW_AT_language
.b8 5                                   // DW_FORM_data2
.b8 3                                   // DW_AT_name
.b8 8                                   // DW_FORM_string
.b8 16                                  // DW_AT_stmt_list
.b8 6                                   // DW_FORM_data4
.b8 27                                  // DW_AT_comp_dir
.b8 8                                   // DW_FORM_string
.b8 0                                   // EOM(1)
.b8 0                                   // EOM(2)
.b8 0                                   // EOM(3)
	}
	.section	.debug_info
	{
.b32 104                                // Length of Unit
.b8 2                                   // DWARF version number
.b8 0
.b32 .debug_abbrev                      // Offset Into Abbrev. Section
.b8 8                                   // Address Size (in bytes)
.b8 1                                   // Abbrev [1] 0xb:0x61 DW_TAG_compile_unit
.b8 116                                 // DW_AT_producer
.b8 114
.b8 105
.b8 116
.b8 111
.b8 110
.b8 0
.b8 2                                   // DW_AT_language
.b8 0
.b8 99                                  // DW_AT_name
.b8 99
.b8 116
.b8 117
.b8 118
.b8 115
.b8 118
.b8 98
.b8 113
.b8 51
.b8 111
.b8 116
.b8 51
.b8 50
.b8 101
.b8 102
.b8 118
.b8 54
.b8 117
.b8 51
.b8 115
.b8 53
.b8 113
.b8 111
.b8 107
.b8 110
.b8 99
.b8 98
.b8 55
.b8 97
.b8 54
.b8 100
.b8 118
.b8 113
.b8 111
.b8 51
.b8 111
.b8 120
.b8 100
.b8 98
.b8 51
.b8 121
.b8 113
.b8 109
.b8 119
.b8 51
.b8 51
.b8 118
.b8 105
.b8 53
.b8 54
.b8 103
.b8 46
.b8 112
.b8 121
.b8 0
.b32 .debug_line                        // DW_AT_stmt_list
.b8 47                                  // DW_AT_comp_dir
.b8 116
.b8 109
.b8 112
.b8 47
.b8 116
.b8 111
.b8 114
.b8 99
.b8 104
.b8 105
.b8 110
.b8 100
.b8 117
.b8 99
.b8 116
.b8 111
.b8 114
.b8 95
.b8 114
.b8 111
.b8 111
.b8 116
.b8 47
.b8 99
.b8 116
.b8 0
	}
	.section	.debug_macinfo	{	}
