//
// Generated by LLVM NVPTX Back-End
//

.version 8.4
.target sm_86
.address_size 64

	// .globl	triton_bmm              // -- Begin function triton_bmm
.extern .shared .align 16 .b8 global_smem[];
                                        // @triton_bmm
.visible .entry triton_bmm(
	.param .u64 .ptr .global .align 1 triton_bmm_param_0,
	.param .u64 .ptr .global .align 1 triton_bmm_param_1,
	.param .u64 .ptr .global .align 1 triton_bmm_param_2,
	.param .u64 .ptr .global .align 1 triton_bmm_param_3
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<6>;
	.reg .b16 	%rs<9>;
	.reg .b32 	%r<257>;
	.reg .f32 	%f<65>;
	.reg .b64 	%rd<14>;
	.loc	1 17 0                          // cormvzvg4tchrilngdz7lkxccm4prckklsdig7gsliqxmpiznigf.py:17:0
$L__func_begin0:
	.loc	1 17 0                          // cormvzvg4tchrilngdz7lkxccm4prckklsdig7gsliqxmpiznigf.py:17:0

// %bb.0:
	ld.param.u64 	%rd6, [triton_bmm_param_0];
	ld.param.u64 	%rd7, [triton_bmm_param_1];
$L__tmp0:
	.loc	1 41 24                         // cormvzvg4tchrilngdz7lkxccm4prckklsdig7gsliqxmpiznigf.py:41:24
	mov.u32 	%r113, %ctaid.x;
	.loc	1 47 22                         // cormvzvg4tchrilngdz7lkxccm4prckklsdig7gsliqxmpiznigf.py:47:22
	shr.s32 	%r114, %r113, 31;
	shr.u32 	%r115, %r114, 25;
	add.s32 	%r116, %r113, %r115;
	shr.s32 	%r117, %r116, 7;
	ld.param.u64 	%rd8, [triton_bmm_param_2];
	.loc	1 48 41                         // cormvzvg4tchrilngdz7lkxccm4prckklsdig7gsliqxmpiznigf.py:48:41
	shl.b32 	%r118, %r117, 3;
	.loc	1 48 30                         // cormvzvg4tchrilngdz7lkxccm4prckklsdig7gsliqxmpiznigf.py:48:30
	sub.s32 	%r119, 16, %r118;
	.loc	1 48 50                         // cormvzvg4tchrilngdz7lkxccm4prckklsdig7gsliqxmpiznigf.py:48:50
	min.s32 	%r120, %r119, 8;
	.loc	1 49 40                         // cormvzvg4tchrilngdz7lkxccm4prckklsdig7gsliqxmpiznigf.py:49:40
	rem.s32 	%r121, %r113, %r120;
	.loc	1 49 34                         // cormvzvg4tchrilngdz7lkxccm4prckklsdig7gsliqxmpiznigf.py:49:34
	add.s32 	%r122, %r121, %r118;
	.loc	1 50 19                         // cormvzvg4tchrilngdz7lkxccm4prckklsdig7gsliqxmpiznigf.py:50:19
	and.b32  	%r123, %r116, -128;
	sub.s32 	%r124, %r113, %r123;
	.loc	1 50 30                         // cormvzvg4tchrilngdz7lkxccm4prckklsdig7gsliqxmpiznigf.py:50:30
	div.s32 	%r125, %r124, %r120;
	.loc	1 52 17                         // cormvzvg4tchrilngdz7lkxccm4prckklsdig7gsliqxmpiznigf.py:52:17
	shl.b32 	%r126, %r122, 5;
	.loc	1 52 40                         // cormvzvg4tchrilngdz7lkxccm4prckklsdig7gsliqxmpiznigf.py:52:40
	mov.u32 	%r127, %tid.x;
	and.b32  	%r128, %r127, 16;
	and.b32  	%r129, %r127, 32;
	and.b32  	%r130, %r127, 64;
	bfe.u32 	%r131, %r127, 3, 4;
	or.b32  	%r132, %r131, 16;
	bfe.u32 	%r133, %r127, 2, 3;
	shr.u32 	%r134, %r129, 2;
	or.b32  	%r135, %r133, %r134;
	shr.u32 	%r136, %r130, 2;
	or.b32  	%r137, %r135, %r136;
	shl.b32 	%r138, %r127, 3;
	and.b32  	%r139, %r138, 8;
	and.b32  	%r140, %r138, 16;
	and.b32  	%r141, %r138, 24;
	.loc	1 52 27                         // cormvzvg4tchrilngdz7lkxccm4prckklsdig7gsliqxmpiznigf.py:52:27
	or.b32  	%r142, %r126, %r131;
	or.b32  	%r143, %r126, %r132;
	or.b32  	%r144, %r137, %r126;
	.loc	1 53 17                         // cormvzvg4tchrilngdz7lkxccm4prckklsdig7gsliqxmpiznigf.py:53:17
	shl.b32 	%r145, %r125, 5;
	.loc	1 53 27                         // cormvzvg4tchrilngdz7lkxccm4prckklsdig7gsliqxmpiznigf.py:53:27
	or.b32  	%r146, %r145, %r131;
	or.b32  	%r147, %r145, %r132;
	or.b32  	%r148, %r145, %r141;
	.loc	1 57 19                         // cormvzvg4tchrilngdz7lkxccm4prckklsdig7gsliqxmpiznigf.py:57:19
	bfe.s32 	%r149, %r122, 26, 1;
	shr.u32 	%r150, %r149, 23;
	add.s32 	%r151, %r142, %r150;
	and.b32  	%r152, %r151, 1048064;
	sub.s32 	%r153, %r142, %r152;
	add.s32 	%r154, %r143, %r150;
	and.b32  	%r155, %r154, 1048064;
	sub.s32 	%r156, %r143, %r155;
	.loc	1 61 19                         // cormvzvg4tchrilngdz7lkxccm4prckklsdig7gsliqxmpiznigf.py:61:19
	bfe.s32 	%r157, %r125, 26, 1;
	shr.u32 	%r158, %r157, 23;
	add.s32 	%r159, %r146, %r158;
	and.b32  	%r160, %r159, 1048064;
	sub.s32 	%r161, %r146, %r160;
	add.s32 	%r162, %r147, %r158;
	and.b32  	%r163, %r162, 1048064;
	sub.s32 	%r164, %r147, %r163;
	.loc	1 65 26                         // cormvzvg4tchrilngdz7lkxccm4prckklsdig7gsliqxmpiznigf.py:65:26
	mov.u32 	%r165, %ctaid.y;
	.loc	1 66 28                         // cormvzvg4tchrilngdz7lkxccm4prckklsdig7gsliqxmpiznigf.py:66:28
	shl.b32 	%r166, %r153, 12;
	shl.b32 	%r167, %r156, 12;
	.loc	1 66 43                         // cormvzvg4tchrilngdz7lkxccm4prckklsdig7gsliqxmpiznigf.py:66:43
	and.b32  	%r168, %r138, 32;
	and.b32  	%r169, %r138, 56;
	.loc	1 66 72                         // cormvzvg4tchrilngdz7lkxccm4prckklsdig7gsliqxmpiznigf.py:66:72
	shl.b32 	%r170, %r165, 6;
	.loc	1 66 40                         // cormvzvg4tchrilngdz7lkxccm4prckklsdig7gsliqxmpiznigf.py:66:40
	or.b32  	%r171, %r169, %r170;
	.loc	1 66 66                         // cormvzvg4tchrilngdz7lkxccm4prckklsdig7gsliqxmpiznigf.py:66:66
	add.s32 	%r172, %r171, %r166;
	add.s32 	%r173, %r171, %r167;
	.loc	1 66 13                         // cormvzvg4tchrilngdz7lkxccm4prckklsdig7gsliqxmpiznigf.py:66:13
	mul.wide.s32 	%rd9, %r172, 2;
	add.s64 	%rd1, %rd6, %rd9;
	mul.wide.s32 	%rd10, %r173, 2;
	add.s64 	%rd2, %rd6, %rd10;
	.loc	1 67 54                         // cormvzvg4tchrilngdz7lkxccm4prckklsdig7gsliqxmpiznigf.py:67:54
	shl.b32 	%r174, %r161, 12;
	shl.b32 	%r175, %r164, 12;
	.loc	1 67 66                         // cormvzvg4tchrilngdz7lkxccm4prckklsdig7gsliqxmpiznigf.py:67:66
	add.s32 	%r176, %r171, %r174;
	add.s32 	%r177, %r171, %r175;
	.loc	1 67 13                         // cormvzvg4tchrilngdz7lkxccm4prckklsdig7gsliqxmpiznigf.py:67:13
	mul.wide.s32 	%rd11, %r176, 2;
	add.s64 	%rd3, %rd7, %rd11;
	mul.wide.s32 	%rd12, %r177, 2;
	add.s64 	%rd4, %rd7, %rd12;
	.loc	1 72 24                         // cormvzvg4tchrilngdz7lkxccm4prckklsdig7gsliqxmpiznigf.py:72:24
	// begin inline asm
	mov.u32 %r1, 0x0;
	mov.u32 %r2, 0x0;
	mov.u32 %r3, 0x0;
	mov.u32 %r4, 0x0;
	ld.global.v4.b32 { %r1, %r2, %r3, %r4 }, [ %rd1 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r5, 0x0;
	mov.u32 %r6, 0x0;
	mov.u32 %r7, 0x0;
	mov.u32 %r8, 0x0;
	ld.global.v4.b32 { %r5, %r6, %r7, %r8 }, [ %rd2 + 0 ];
	// end inline asm
	and.b32  	%r178, %r127, 24;
	xor.b32  	%r179, %r169, %r178;
	xor.b32  	%r180, %r179, %r129;
	shl.b32 	%r181, %r180, 1;
	shl.b32 	%r182, %r131, 7;
	or.b32  	%r183, %r182, %r181;
	mov.u32 	%r184, global_smem;
	add.s32 	%r185, %r184, %r183;
	st.shared.v4.b32 	[%r185], {%r1, %r2, %r3, %r4};
	st.shared.v4.b32 	[%r185+2048], {%r5, %r6, %r7, %r8};
	.loc	1 73 24                         // cormvzvg4tchrilngdz7lkxccm4prckklsdig7gsliqxmpiznigf.py:73:24
	// begin inline asm
	mov.u32 %r9, 0x0;
	mov.u32 %r10, 0x0;
	mov.u32 %r11, 0x0;
	mov.u32 %r12, 0x0;
	ld.global.v4.b32 { %r9, %r10, %r11, %r12 }, [ %rd3 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r13, 0x0;
	mov.u32 %r14, 0x0;
	mov.u32 %r15, 0x0;
	mov.u32 %r16, 0x0;
	ld.global.v4.b32 { %r13, %r14, %r15, %r16 }, [ %rd4 + 0 ];
	// end inline asm
	add.s32 	%r186, %r184, 4096;
	add.s32 	%r187, %r186, %r183;
	st.shared.v4.b32 	[%r187], {%r9, %r10, %r11, %r12};
	st.shared.v4.b32 	[%r187+2048], {%r13, %r14, %r15, %r16};
	.loc	1 72 24                         // cormvzvg4tchrilngdz7lkxccm4prckklsdig7gsliqxmpiznigf.py:72:24
	bar.sync 	0;
	and.b32  	%r188, %r127, 7;
	and.b32  	%r189, %r127, 15;
	shr.u32 	%r190, %r128, 1;
	xor.b32  	%r191, %r169, %r190;
	or.b32  	%r192, %r136, %r189;
	shl.b32 	%r193, %r192, 6;
	or.b32  	%r194, %r193, %r191;
	shl.b32 	%r195, %r194, 1;
	add.s32 	%r21, %r184, %r195;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r57, %r58, %r59, %r60}, [%r21];
	// end inline asm
	or.b32  	%r196, %r139, 16;
	xor.b32  	%r197, %r196, %r140;
	or.b32  	%r198, %r197, %r168;
	xor.b32  	%r199, %r198, %r190;
	or.b32  	%r200, %r199, %r193;
	shl.b32 	%r201, %r200, 1;
	add.s32 	%r26, %r184, %r201;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r69, %r70, %r71, %r72}, [%r26];
	// end inline asm
	or.b32  	%r202, %r141, 32;
	xor.b32  	%r203, %r202, %r168;
	xor.b32  	%r204, %r203, %r190;
	or.b32  	%r205, %r204, %r193;
	shl.b32 	%r206, %r205, 1;
	add.s32 	%r31, %r184, %r206;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r81, %r82, %r83, %r84}, [%r31];
	// end inline asm
	or.b32  	%r207, %r139, 48;
	and.b32  	%r208, %r138, 48;
	or.b32  	%r209, %r190, %r208;
	xor.b32  	%r210, %r209, %r207;
	or.b32  	%r211, %r210, %r193;
	shl.b32 	%r212, %r211, 1;
	add.s32 	%r36, %r184, %r212;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r93, %r94, %r95, %r96}, [%r36];
	// end inline asm
	.loc	1 73 24                         // cormvzvg4tchrilngdz7lkxccm4prckklsdig7gsliqxmpiznigf.py:73:24
	or.b32  	%r213, %r134, %r188;
	shl.b32 	%r214, %r179, 1;
	shl.b32 	%r215, %r213, 7;
	or.b32  	%r216, %r215, %r214;
	add.s32 	%r41, %r186, %r216;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r61, %r62, %r73, %r74}, [%r41];
	// end inline asm
	xor.b32  	%r217, %r203, %r178;
	shl.b32 	%r218, %r217, 1;
	add.s32 	%r219, %r186, %r218;
	add.s32 	%r46, %r219, %r215;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r85, %r86, %r97, %r98}, [%r46];
	// end inline asm
	add.s32 	%r51, %r41, 2048;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r67, %r68, %r79, %r80}, [%r51];
	// end inline asm
	add.s32 	%r56, %r46, 2048;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 {%r91, %r92, %r103, %r104}, [%r56];
	// end inline asm
	mov.f32 	%f25, 0f00000000;
	.loc	1 77 25                         // cormvzvg4tchrilngdz7lkxccm4prckklsdig7gsliqxmpiznigf.py:77:25
	mov.f32 	%f17, %f25;
	mov.f32 	%f18, %f25;
	mov.f32 	%f19, %f25;
	mov.f32 	%f20, %f25;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f17, %f18, %f19, %f20 }, { %r57, %r58, %r59, %r60 }, { %r61, %r62 }, { %f17, %f18, %f19, %f20 };
	// end inline asm
	mov.f32 	%f26, %f25;
	mov.f32 	%f27, %f25;
	mov.f32 	%f28, %f25;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f25, %f26, %f27, %f28 }, { %r57, %r58, %r59, %r60 }, { %r67, %r68 }, { %f25, %f26, %f27, %f28 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f17, %f18, %f19, %f20 }, { %r69, %r70, %r71, %r72 }, { %r73, %r74 }, { %f17, %f18, %f19, %f20 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f25, %f26, %f27, %f28 }, { %r69, %r70, %r71, %r72 }, { %r79, %r80 }, { %f25, %f26, %f27, %f28 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f17, %f18, %f19, %f20 }, { %r81, %r82, %r83, %r84 }, { %r85, %r86 }, { %f17, %f18, %f19, %f20 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f25, %f26, %f27, %f28 }, { %r81, %r82, %r83, %r84 }, { %r91, %r92 }, { %f25, %f26, %f27, %f28 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f17, %f18, %f19, %f20 }, { %r93, %r94, %r95, %r96 }, { %r97, %r98 }, { %f17, %f18, %f19, %f20 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f25, %f26, %f27, %f28 }, { %r93, %r94, %r95, %r96 }, { %r103, %r104 }, { %f25, %f26, %f27, %f28 };
	// end inline asm
	.loc	1 87 26                         // cormvzvg4tchrilngdz7lkxccm4prckklsdig7gsliqxmpiznigf.py:87:26
	max.s32 	%r220, %r144, %r148;
	setp.lt.s32 	%p5, %r220, 512;
	.loc	1 90 25                         // cormvzvg4tchrilngdz7lkxccm4prckklsdig7gsliqxmpiznigf.py:90:25
	shl.b32 	%r221, %r144, 9;
	.loc	1 90 40                         // cormvzvg4tchrilngdz7lkxccm4prckklsdig7gsliqxmpiznigf.py:90:40
	shl.b32 	%r222, %r165, 18;
	.loc	1 90 21                         // cormvzvg4tchrilngdz7lkxccm4prckklsdig7gsliqxmpiznigf.py:90:21
	add.s32 	%r223, %r148, %r222;
	.loc	1 90 33                         // cormvzvg4tchrilngdz7lkxccm4prckklsdig7gsliqxmpiznigf.py:90:33
	add.s32 	%r224, %r223, %r221;
	.loc	1 91 25                         // cormvzvg4tchrilngdz7lkxccm4prckklsdig7gsliqxmpiznigf.py:91:25
	mul.wide.s32 	%rd13, %r224, 2;
	add.s64 	%rd5, %rd8, %rd13;
	.loc	1 91 67                         // cormvzvg4tchrilngdz7lkxccm4prckklsdig7gsliqxmpiznigf.py:91:67
	cvt.rn.bf16.f32 	%rs1, %f17;
	cvt.rn.bf16.f32 	%rs2, %f18;
	cvt.rn.bf16.f32 	%rs3, %f19;
	cvt.rn.bf16.f32 	%rs4, %f20;
	cvt.rn.bf16.f32 	%rs5, %f25;
	cvt.rn.bf16.f32 	%rs6, %f26;
	cvt.rn.bf16.f32 	%rs7, %f27;
	cvt.rn.bf16.f32 	%rs8, %f28;
	bar.sync 	0;
	shl.b32 	%r225, %r127, 1;
	and.b32  	%r226, %r225, 6;
	and.b32  	%r227, %r138, 64;
	or.b32  	%r228, %r226, %r227;
	or.b32  	%r229, %r228, %r168;
	shl.b32 	%r230, %r128, 3;
	or.b32  	%r231, %r229, %r230;
	or.b32  	%r232, %r231, %r134;
	shl.b32 	%r233, %r130, 3;
	or.b32  	%r234, %r232, %r233;
	and.b32  	%r235, %r138, 376;
	or.b32  	%r236, %r230, %r235;
	or.b32  	%r237, %r236, %r233;
	shr.u32 	%r238, %r234, 1;
	and.b32  	%r239, %r238, 2147483632;
	add.s32 	%r240, %r184, %r239;
	shl.b32 	%r241, %r234, 1;
	add.s32 	%r105, %r240, %r241;
	mov.pred 	%p1, -1;
	// begin inline asm
	@%p1 st.shared.v2.b16 [ %r105 + 0 ], { %rs1, %rs2 };
	// end inline asm
	or.b32  	%r242, %r234, 256;
	shr.u32 	%r243, %r242, 1;
	and.b32  	%r244, %r243, 2147483632;
	add.s32 	%r245, %r184, %r244;
	shl.b32 	%r246, %r242, 1;
	add.s32 	%r106, %r245, %r246;
	// begin inline asm
	@%p1 st.shared.v2.b16 [ %r106 + 0 ], { %rs3, %rs4 };
	// end inline asm
	add.s32 	%r107, %r105, 32;
	// begin inline asm
	@%p1 st.shared.v2.b16 [ %r107 + 0 ], { %rs5, %rs6 };
	// end inline asm
	or.b32  	%r247, %r234, 272;
	shr.u32 	%r248, %r247, 1;
	and.b32  	%r249, %r248, 2147483632;
	add.s32 	%r250, %r184, %r249;
	shl.b32 	%r251, %r247, 1;
	add.s32 	%r108, %r250, %r251;
	// begin inline asm
	@%p1 st.shared.v2.b16 [ %r108 + 0 ], { %rs7, %rs8 };
	// end inline asm
	bar.sync 	0;
	shr.u32 	%r252, %r237, 1;
	and.b32  	%r253, %r252, 496;
	add.s32 	%r254, %r184, %r253;
	shl.b32 	%r255, %r237, 1;
	add.s32 	%r256, %r254, %r255;
	ld.shared.v4.u32 	{%r109, %r110, %r111, %r112}, [%r256];
	// begin inline asm
	@%p5 st.global.v4.b32 [ %rd5 + 0 ], { %r109, %r110, %r111, %r112 };
	// end inline asm
	.loc	1 91 4                          // cormvzvg4tchrilngdz7lkxccm4prckklsdig7gsliqxmpiznigf.py:91:4
	ret;
$L__tmp1:
$L__func_end0:
                                        // -- End function
}
	.file	1 "/tmp/torchinductor_root/or/cormvzvg4tchrilngdz7lkxccm4prckklsdig7gsliqxmpiznigf.py"
	.section	.debug_abbrev
	{
.b8 1                                   // Abbreviation Code
.b8 17                                  // DW_TAG_compile_unit
.b8 0                                   // DW_CHILDREN_no
.b8 37                                  // DW_AT_producer
.b8 8                                   // DW_FORM_string
.b8 19                                  // DW_AT_language
.b8 5                                   // DW_FORM_data2
.b8 3                                   // DW_AT_name
.b8 8                                   // DW_FORM_string
.b8 16                                  // DW_AT_stmt_list
.b8 6                                   // DW_FORM_data4
.b8 27                                  // DW_AT_comp_dir
.b8 8                                   // DW_FORM_string
.b8 0                                   // EOM(1)
.b8 0                                   // EOM(2)
.b8 0                                   // EOM(3)
	}
	.section	.debug_info
	{
.b32 104                                // Length of Unit
.b8 2                                   // DWARF version number
.b8 0
.b32 .debug_abbrev                      // Offset Into Abbrev. Section
.b8 8                                   // Address Size (in bytes)
.b8 1                                   // Abbrev [1] 0xb:0x61 DW_TAG_compile_unit
.b8 116                                 // DW_AT_producer
.b8 114
.b8 105
.b8 116
.b8 111
.b8 110
.b8 0
.b8 2                                   // DW_AT_language
.b8 0
.b8 99                                  // DW_AT_name
.b8 111
.b8 114
.b8 109
.b8 118
.b8 122
.b8 118
.b8 103
.b8 52
.b8 116
.b8 99
.b8 104
.b8 114
.b8 105
.b8 108
.b8 110
.b8 103
.b8 100
.b8 122
.b8 55
.b8 108
.b8 107
.b8 120
.b8 99
.b8 99
.b8 109
.b8 52
.b8 112
.b8 114
.b8 99
.b8 107
.b8 107
.b8 108
.b8 115
.b8 100
.b8 105
.b8 103
.b8 55
.b8 103
.b8 115
.b8 108
.b8 105
.b8 113
.b8 120
.b8 109
.b8 112
.b8 105
.b8 122
.b8 110
.b8 105
.b8 103
.b8 102
.b8 46
.b8 112
.b8 121
.b8 0
.b32 .debug_line                        // DW_AT_stmt_list
.b8 47                                  // DW_AT_comp_dir
.b8 116
.b8 109
.b8 112
.b8 47
.b8 116
.b8 111
.b8 114
.b8 99
.b8 104
.b8 105
.b8 110
.b8 100
.b8 117
.b8 99
.b8 116
.b8 111
.b8 114
.b8 95
.b8 114
.b8 111
.b8 111
.b8 116
.b8 47
.b8 111
.b8 114
.b8 0
	}
	.section	.debug_macinfo	{	}
